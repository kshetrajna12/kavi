# Kavi v2 Bootstrap Plan (Sparkstation)

You are building the first working version of Kavi v2 in a brand new empty repo.
Target environment: Sparkstation (DGX Spark) running local models; Python-first.
Goal: ship a minimal, governed “self-building” spine. Do NOT build agents/features yet.

## Non-Negotiable Invariants (must be enforced in code)
1) LLM output never gets executed directly.
2) All code changes happen via patches/branches, never by eval’ing generated code.
3) A “skill” is unusable until promoted to TRUSTED.
4) Secrets are never passed to the coding agent. Runtime secrets are injected only when calling TRUSTED skills.
5) Push/background can only PROPOSE. Only pull/user can COMMIT.
6) Artifacts are mandatory: every meaningful output must be written as a file (markdown) + recorded in ledger.
7) Memory/retrieval is rebuildable and non-canonical. Canonical is ledger + artifacts.

## MVP Deliverable (what “done” means)
A CLI that can:
- create a skill proposal (PROPOSED)
- invoke “build skill” workflow (calls Claude Code to generate code + tests + docs for a skill)
- verify the patch (ruff/mypy/pytest + policy scan)
- promote the skill to TRUSTED
- write artifacts to an Obsidian-compatible folder
- record everything in a local ledger (SQLite first; Postgres later)

Plus:
- a sample “hello skill” generated by Claude Code and promoted to TRUSTED

No web UI. No voice. No Slack. No “agents”. Just the spine.

## Repo Layout to Create
kavi/
  README.md
  KAVI_V2_INVARIANTS.md
  pyproject.toml
  src/kavi/
    __init__.py
    cli.py
    config.py
    ledger/
      __init__.py
      db.py
      models.py
    artifacts/
      __init__.py
      writer.py
    policies/
      __init__.py
      scanner.py
      policy.yaml
    skills/
      __init__.py
      registry.yaml
      loader.py
      base.py
    forge/
      __init__.py
      propose.py
      build.py
      verify.py
      promote.py
  tests/
    test_ledger.py
    test_artifacts.py
    test_policy_scanner.py
    test_skills_loader.py
    test_forge_flow.py

## Technology Choices (do not bikeshed)
- Python 3.11+
- Typer for CLI
- Pydantic for schemas
- SQLite for ledger in MVP (file-based). Use SQLModel or plain sqlite3 with typed models.
- ruff + mypy + pytest
- No Docker required for MVP
- No external services

## Ledger (SQLite) – Minimal Schema
Tables:
1) skill_proposals:
   - id (uuid)
   - name
   - description
   - io_schema_json
   - side_effect_class (READ_ONLY|FILE_WRITE|NETWORK|MONEY|MESSAGING)
   - required_secrets_json (list)
   - status (PROPOSED|REJECTED|BUILT|VERIFIED|TRUSTED)
   - created_at

2) builds:
   - id (uuid)
   - proposal_id
   - branch_name
   - started_at
   - finished_at
   - status (STARTED|FAILED|SUCCEEDED)
   - summary (text)

3) verifications:
   - id (uuid)
   - proposal_id
   - status (FAILED|PASSED)
   - ruff_ok (bool)
   - mypy_ok (bool)
   - pytest_ok (bool)
   - policy_ok (bool)
   - report_path (artifact path)
   - created_at

4) promotions:
   - id (uuid)
   - proposal_id
   - from_status
   - to_status
   - approved_by (string "kshetrajna")
   - created_at

5) artifacts:
   - id (uuid)
   - kind (SKILL_SPEC|PATCH_SUMMARY|VERIFICATION_REPORT|NOTE)
   - path
   - sha256
   - created_at
   - related_id (proposal_id/build_id/etc)

## Skill Registry
File: src/kavi/skills/registry.yaml
Contains TRUSTED skills only. Each entry:
- name
- module_path (python import)
- description
- input_model (pydantic class path)
- output_model (pydantic class path)
- side_effect_class
- required_secrets
- version
- hash

## Policy Scanner (must exist in MVP)
File: src/kavi/policies/policy.yaml
- forbidden_imports: ["subprocess", "os.system", "pty", "paramiko"]
- allowed_network: only via a wrapper module (not implemented yet; so disallow network in MVP)
- allowed_write_paths: ["./vault_out/", "./artifacts_out/"]
- forbid_dynamic_exec: true (block eval/exec)
Implement scanner that:
- scans src/kavi/skills/*.py for forbidden imports / exec / eval usage
- produces a report artifact

## Artifact Writer
Write markdown and reports to:
- ./vault_out/Inbox/AI/
- ./artifacts_out/
Return content hash + path and store in ledger.

## CLI Commands (must implement)
kavi propose-skill --name ... --desc ... --side-effect ... --io-schema-json ...
  -> creates proposal row + writes SPEC artifact markdown

kavi build-skill <proposal_id>
  -> creates git branch "skill/<name>-<shortid>"
  -> writes BUILD_PACKET.md (spec + policy summary + required files)
  -> invokes Claude Code (you can stub invocation with a placeholder function that prints instructions; but structure must exist)
  -> marks build row

kavi verify-skill <proposal_id>
  -> runs ruff/mypy/pytest and policy scanner
  -> writes VERIFICATION_REPORT.md artifact
  -> records verification row

kavi promote-skill <proposal_id>
  -> only allowed if verification passed
  -> updates registry.yaml with the new TRUSTED skill entry (compute hash)
  -> updates proposal status TRUSTED
  -> records promotion row

kavi list-skills
  -> shows trusted skills from registry

kavi run-skill <skill_name> --json '{...}'
  -> loads skill, validates input schema, executes, returns output
  -> enforce side-effect class: for MVP only allow READ_ONLY and FILE_WRITE with allowlisted paths

## First Skill to Build (to validate the pipeline)
Name: write_note
- input: { "path": "Inbox/AI/test.md", "title": "string", "body": "string" }
- output: { "written_path": "string", "sha256": "string" }
Behavior: writes a markdown note into ./vault_out/<path> and returns hashes.
This skill should be generated through the forge workflow (proposal → build → verify → promote).

## Testing Requirements
- Unit tests for ledger create/read/update
- Policy scanner catches forbidden imports + eval/exec
- Forge flow test that:
  - creates proposal
  - (stub) build step writes build packet
  - verify step runs checks (you can simulate ruff/mypy/pytest in tests but real commands should exist)
  - promote step updates registry.yaml
- Skills loader test that can import and run write_note after promotion

## Implementation Notes
- Keep code small and modular. Avoid “agent frameworks”.
- No async required in MVP.
- Use deterministic UUIDs where appropriate.
- Provide clear docstrings and README usage examples.

